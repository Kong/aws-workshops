<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AWS Modernization Workshop on Self-Paced</title>
    <link>/</link>
    <description>Recent content in AWS Modernization Workshop on Self-Paced</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-US</language><atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>AWS Cognito</title>
      <link>/070_kong_cognito/071_cognito.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/070_kong_cognito/071_cognito.html</guid>
      <description>Creating AWS Cognito First of all, let&amp;rsquo;s create a Cognito instance using the AWS Console
 Go to Cognito console and click on &amp;ldquo;Managed User Pools&amp;rdquo; and on &amp;ldquo;Create a user pool&amp;rdquo;. Name your pool as &amp;ldquo;kongpool&amp;rdquo; and click on &amp;ldquo;Step through settings&amp;rdquo;. Select “Email address or phone number” and, under that, select “Allow email addresses”. Select the following standard attributes as required  email family name given name  Click on &amp;ldquo;Next step&amp;rdquo;.</description>
    </item>
    
    <item>
      <title>Konnect Control Plane and Data Plane Setup</title>
      <link>/040_kong_enterprise_setup/041_data_plane_and_control_plane_setup.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/040_kong_enterprise_setup/041_data_plane_and_control_plane_setup.html</guid>
      <description>Konnect Control Plane and Data Plane Create the Digital Certificate and Private Key pair In Hybrid mode, a mutual TLS handshake (mTLS) is used for authentication so the actual private key is never transferred on the network, and communication between CP and DP nodes is secure.
Before using Hybrid mode, you need a certificate/key pair. Kong Gateway provides two modes for handling certificate/key pairs:
 Shared mode: (Default) Use the Kong CLI to generate a certificate/key pair, then distribute copies across nodes.</description>
    </item>
    
    <item>
      <title>Proxy Caching</title>
      <link>/060_kong_ingress/061_cache.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/060_kong_ingress/061_cache.html</guid>
      <description>Proxy Caching Policy Definition Since we have the Microservice exposed through a route defined in the Ingress Controller, let&amp;rsquo;s apply the Proxy Caching plugin to cache the data coming from it.
Create the plugin
cat &amp;lt;&amp;lt;EOF | kubectl apply -f - apiVersion: configuration.konghq.com/v1 kind: KongPlugin metadata: name: proxycache namespace: default config: cache_ttl: 30 strategy: memory content_type: [&amp;#34;text/html; charset=utf-8&amp;#34;] plugin: proxy-cache EOF If you want to delete it run:
$ kubectl delete kongplugin proxycache Apply the plugin to the route</description>
    </item>
    
    <item>
      <title>Konnect Data Plane Elasticity</title>
      <link>/040_kong_enterprise_setup/042_hpa.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/040_kong_enterprise_setup/042_hpa.html</guid>
      <description>Konnect Data Plane Elasticity One of the most important capabilities provided by Kubernetes is to easily scale out a Deployment. With a single command we can create or terminate pod replicas in order to optimaly support a given throughtput.
This capability is specially interesting for Kubernetes applications like Kong for Kubernetes Ingress Controller.
Here&amp;rsquo;s our deployment before scaling it out:
$ kubectl get service -n kong-dp NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kong-dp-kong-proxy LoadBalancer 10.</description>
    </item>
    
    <item>
      <title>OpenId Connect Plugin</title>
      <link>/070_kong_cognito/073_oidc_plugin.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/070_kong_cognito/073_oidc_plugin.html</guid>
      <description>Instantiating an OIDC plugin cat &amp;lt;&amp;lt;EOF | kubectl apply -f - apiVersion: configuration.konghq.com/v1 kind: KongPlugin metadata: name: oidc namespace: default config: client_id: [2bstc80hrpbppslrev646e1g6e] client_secret: [hqg1pr8s1khm4thi7n4efk6tdblhr2f4cpre51ct4tvlgbglvql] issuer: &amp;#34;https://cognito-idp.us-east-1.amazonaws.com/us-east-1_XZkYwawRq/.well-known/openid-configuration&amp;#34; cache_ttl: 10 redirect_uri: [&amp;#34;https://a946e3cab079a49a1b6661ab62d5585f-2135097986.us-east-1.elb.amazonaws.com/sampleroute/hello&amp;#34;] plugin: openid-connect EOF Observations:
 The issuer URL follows the format: https://cognito-idp.{region}.amazonaws.com/{userPoolId} OIDC plugin generates, by default the &amp;ldquo;redirect uri&amp;rdquo; based on its port (8443). The &amp;ldquo;redirect_uri&amp;rdquo; parameter defines the URI to be used to redirect the user after getting authenticated.</description>
    </item>
    
    <item>
      <title>Prometheus and Grafana</title>
      <link>/040_kong_enterprise_setup/043_prometheus_grafana.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/040_kong_enterprise_setup/043_prometheus_grafana.html</guid>
      <description>Prometheus and Grafana From the Observability perspective, we&amp;rsquo;re going to use Prometheus and Grafana. Two levels of monitoring are possible:
 Kubernetes monitoring: Prometheus and Grafana monitor Kong Data Plane Deployment in terms of CPU, memory and networking consumption as well as HPA and the number of Pod replicas, just like any Kubernetes Deployment. Kong Data Plane monitoring: Prometheus and Grafana expose metrics the Kong Data Planes replicas provide in terms of API consumption including number of processed requests, etc.</description>
    </item>
    
    <item>
      <title>Rate Limiting Policy Definition</title>
      <link>/060_kong_ingress/063_rate_limiting.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/060_kong_ingress/063_rate_limiting.html</guid>
      <description>Rate Limiting Policy Definition Now let&amp;rsquo;s protect our upstream service with a Rate Limiting policy.
Create the plugin
cat &amp;lt;&amp;lt;EOF | kubectl apply -f - apiVersion: configuration.konghq.com/v1 kind: KongPlugin metadata: name: rl-by-minute namespace: default config: minute: 3 policy: local plugin: rate-limiting EOF If you want to delete it run:
$ kubectl delete kongplugin rl-by-minute Apply the plugin to the route
kubectl patch ingress sampleroute -p &amp;#39;{&amp;#34;metadata&amp;#34;:{&amp;#34;annotations&amp;#34;:{&amp;#34;konghq.com/plugins&amp;#34;:&amp;#34;proxycache, rl-by-minute&amp;#34;}}}&amp;#39; In case you want to disapply the plugin to the ingress run:</description>
    </item>
    
    <item>
      <title>API Key Policy Definition</title>
      <link>/060_kong_ingress/064_api_key.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/060_kong_ingress/064_api_key.html</guid>
      <description>API Key Policy Definition Now, let&amp;rsquo;s add an API Key Policy to this route:
Create the plugin
cat &amp;lt;&amp;lt;EOF | kubectl apply -f - apiVersion: configuration.konghq.com/v1 kind: KongPlugin metadata: name: apikey namespace: default plugin: key-auth EOF If you want to delete it run:
$ kubectl delete kongplugin apikey Now, let&amp;rsquo;s add an API Key Policy to this route keeping the original Rate Limiting plugin:
kubectl patch ingress sampleroute -p &amp;#39;{&amp;#34;metadata&amp;#34;:{&amp;#34;annotations&amp;#34;:{&amp;#34;konghq.</description>
    </item>
    
    <item>
      <title>ELK Stack</title>
      <link>/040_kong_enterprise_setup/044_elk.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/040_kong_enterprise_setup/044_elk.html</guid>
      <description>ELK Stack From the Monitoring and Log Processing perspective, it&amp;rsquo;s important to integrate Kong Konnect Enterprise with a best-of-breed product to externalize all information related to processed requests and allow users to define dashboard, alerts, reports, etc.
This part of the tutorial shows how to configure the real-time integration between Kong Enterprise and Elastic products: Elasticsearch, Kibana and Logstash.
Elasticsearch Install Elasticsearch
 kubectl create namespace elk helm install elk elastic/elasticsearch -n elk --set replicas=1 --set minimumMasterNodes=1  Logstash Fetch the Charts and Update values.</description>
    </item>
    
    <item>
      <title>Redis</title>
      <link>/040_kong_enterprise_setup/045_redis.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/040_kong_enterprise_setup/045_redis.html</guid>
      <description>Redis Redis can be consumed by Kong Data Plane for two use cases:
 Caching: data coming from the upstream services can be cached to provide even better response and latence times Rate Limiting: to allow the multiple instances of the Kong Data Plane to process the same rate limiting counters  We&amp;rsquo;re going to explore Kong Data Plane and Redis integration in the next sections of the workshop.</description>
    </item>
    
    <item>
      <title>Set up Ingress rule for Kong Ingress</title>
      <link>/060_kong_ingress/065_ingress_rule.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/060_kong_ingress/065_ingress_rule.html</guid>
      <description>Set up Ingress rule for Kong Ingress In this learning lab, you will learn how to use the KongIngress resource to control proxy behavior.
Deploy the new Service cat &amp;lt;&amp;lt;EOF | kubectl apply -f - apiVersion: v1 kind: Service metadata: labels: app: echo name: echo spec: ports: - port: 8080 name: high protocol: TCP targetPort: 8080 - port: 80 name: low protocol: TCP targetPort: 8080 selector: app: echo --- apiVersion: apps/v1 kind: Deployment metadata: labels: app: echo name: echo spec: replicas: 1 selector: matchLabels: app: echo strategy: {} template: metadata: creationTimestamp: null labels: app: echo spec: containers: - image: gcr.</description>
    </item>
    
    <item>
      <title>Configuring a fallback service</title>
      <link>/060_kong_ingress/066_fallback_service.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/060_kong_ingress/066_fallback_service.html</guid>
      <description>Configuring a fallback service In this learning lab, you will learn how to setup a fallback service using Ingress resource. The fallback service will receive all requests that don&amp;rsquo;t match against any of the defined Ingress rules.
This can be useful for scenarios where you would like to return a 404 page to the end user if the user clicks on a dead link or inputs an incorrect URL.</description>
    </item>
    
    <item>
      <title>Sample App Installation</title>
      <link>/040_kong_enterprise_setup/046_sample_application.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/040_kong_enterprise_setup/046_sample_application.html</guid>
      <description>Sample App Installation The going to deploy a very basic application to our EKS Cluster and protect it with Kong for Kubernetes Ingress Controller. The app simply returns the current datetime.
Deploy Sample App cat &amp;lt;&amp;lt;EOF | kubectl apply -f - apiVersion: v1 kind: Service metadata: name: sample namespace: default labels: app: sample spec: type: ClusterIP ports: - port: 5000 name: http selector: app: sample --- apiVersion: apps/v1 kind: Deployment metadata: name: sample namespace: default spec: replicas: 1 selector: matchLabels: app: sample template: metadata: labels: app: sample version: v1 spec: containers: - name: sample image: claudioacquaviva/sampleapp ports: - containerPort: 5000 EOF Check the Deployment</description>
    </item>
    
    <item>
      <title>HTTP/S Redirect</title>
      <link>/060_kong_ingress/067_https_redirect.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/060_kong_ingress/067_https_redirect.html</guid>
      <description>HTTP/S Redirect This guide walks through how to configure Kong Ingress Controller to redirect HTTP request to HTTPS so that all communication from the external world to your APIs and micro services is encrypted.
Create the Ingress We&amp;rsquo;re going to create an Ingress for the Echo Service we deployed previously
cat &amp;lt;&amp;lt;EOF | kubectl apply -f - apiVersion: extensions/v1beta1 kind: Ingress metadata: name: demo-redirect annotations: konghq.com/strip-path: &amp;#34;true&amp;#34; kubernetes.io/ingress.class: kong spec: rules: - http: paths: - path: /foo-redirect backend: serviceName: echo servicePort: 80 EOF Consume the Ingress $ http a6bf3f71a14a64dba850480616af8fc9-1188819016.</description>
    </item>
    
    <item>
      <title>Simple Kong Ingress</title>
      <link>/040_kong_enterprise_setup/047_simple_kong_ingress.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/040_kong_enterprise_setup/047_simple_kong_ingress.html</guid>
      <description>Kong Ingress Create an Ingress CRDs In order to expose &amp;ldquo;sample&amp;rdquo; through K4K8S, we&amp;rsquo;re going to create a specific &amp;ldquo;/sampleroute&amp;rdquo; route. Initially, the route is totally open and can be consumed freely. The next sections enable, as the name suggests, an API Key and a Rate Limiting mechanisms to protect the route.
cat &amp;lt;&amp;lt;EOF | kubectl apply -f - apiVersion: extensions/v1beta1 kind: Ingress metadata: name: sampleroute namespace: default annotations: konghq.</description>
    </item>
    
    <item>
      <title>Redis for Rate Limiting</title>
      <link>/060_kong_ingress/068_redis_ratelimiting.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/060_kong_ingress/068_redis_ratelimiting.html</guid>
      <description>Redis for Rate Limiting Kong can rate-limit your traffic without any external dependency. In such a case, Kong stores the request counters in-memory and each Kong node applies the rate-limiting policy independently. There is no synchronization of information being done in this case. But if Redis is available in your cluster, Kong can take advantage of it and synchronize the rate-limit information across multiple Kong nodes and enforce a slightly different rate-limiting policy.</description>
    </item>
    
    <item>
      <title>Foreword</title>
      <link>/010_introduction/10_foreword.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/010_introduction/10_foreword.html</guid>
      <description>Kong Konnect Kong Konnect is a service connectivity platform that provides technology teams at multi-cloud and hybrid organizations the “architectural freedom” to build APIs and services anywhere. Kong’s service connectivity platform provides a ﬂexible, technology-agnostic platform that supports any cloud, platform, protocol and architecture. Kong Enterprise supports the full lifecycle of service management, enabling users to easily design, test, secure, deploy, monitor, monetize and version their APIs. Over 250 enterprises trust Kong Enterprise to reduce time to market by bringing applications and services to market faster, as well as increase infrastructure ROI by maximizing resource efficiency through improved automation and reduced overhead.</description>
    </item>
    
    <item>
      <title>Provisioning EKS infrastructure</title>
      <link>/030_aws_setup_for_hosting_kong/30_provisiong_eks_infrastructure.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/030_aws_setup_for_hosting_kong/30_provisiong_eks_infrastructure.html</guid>
      <description>Creating an EKS Cluster Before getting started with the workshop, we recommend to have an EKS Cluster already available. If you don&amp;rsquo;t have one, please, follow these instructions.
Creating an EKS Cluster We&amp;rsquo;re going to use eksctl to create our EKS Cluster.
 $ eksctl create cluster --name K4K8S --version 1.21 --region us-east-1 --without-nodegroup 2021-09-29 20:23:41 [ℹ] eksctl version 0.67.0 2021-09-29 20:23:41 [ℹ] using region us-east-1 2021-09-29 20:23:43 [ℹ] setting availability zones to [us-east-1f us-east-1c] 2021-09-29 20:23:43 [ℹ] subnets for us-east-1f - public:192.</description>
    </item>
    
    <item>
      <title>The Challenge</title>
      <link>/010_introduction/12_problem_to_solve.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/010_introduction/12_problem_to_solve.html</guid>
      <description>The Problem Every organization is under pressure to innovate by providing compelling digital experiences. Organizations overcome this challenge through applications that are built with modern architectures using microservices and containers, managed through Kubernetes. These modern methods deliver the agility needs of the businesses.
Organizations break down legacy monolithic applications into smaller modern services, or they build new cloud native apps using microservices. The number of APIs is exploding, and connectivity between services becomes the critical backbone of your applications.</description>
    </item>
    
    <item>
      <title>What is Kong?</title>
      <link>/010_introduction/14_partner.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/010_introduction/14_partner.html</guid>
      <description>Kong Konnect Enterprise The Service Connectivity Platform End-to-end service connectivity The platform integrates an API gateway, service mesh and ingress to provide end-to-end service connectivity across the full API lifecycle. It is the only platform that provides end-to-end connectivity between services within applications and across applications as well as exposes services at the edge.
Architectural freedom You can abstract network and security concerns from services so that developers can focus on building apps instead of pipes.</description>
    </item>
    
    <item>
      <title>Workshop Prerequisites</title>
      <link>/010_introduction/16_workshop_prerequisites.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/010_introduction/16_workshop_prerequisites.html</guid>
      <description>Workshop Prerequisites There are a few prerequisite tasks you must perform before getting started on this workshop. These are:
 access to an AWS account with proper permissions. eksctl kubectl
 httpie and curl jq fortio  In the next section, you will be instructed on how to configure all the prerequisite task stated above.</description>
    </item>
    
    <item>
      <title>Getting Started</title>
      <link>/010_introduction/18_getting_started.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/010_introduction/18_getting_started.html</guid>
      <description>Getting Started Kong Gateway Enterprise is Kong’s API gateway with enterprise functionality. As part of Kong Konnect, the gateway brokers an organization’s information across all services by allowing customers to manage the full lifecycle of services and APIs. On top of that, it enables users to simplify the management of APIs and microservices across hybrid-cloud and multi-cloud deployments.
Kong Gateway is designed to run on decentralized architectures, leveraging workflow automation and modern GitOps practices.</description>
    </item>
    
    <item>
      <title>1. AWS Event Engine</title>
      <link>/020_event_engine_setup/20_aws_event_engine.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/020_event_engine_setup/20_aws_event_engine.html</guid>
      <description>Attending an AWS hosted event To complete this workshop, you will be provided with an AWS account via the AWS Event Engine service. A team hash will be provided to you by event staff.
If you are currently logged in to an AWS Account, you can log out using this link
 Logging into Event Engine Dashboard  Connect to the portal by clicking the button or browsing to https://dashboard.</description>
    </item>
    
    <item>
      <title>2. Set up EKS Cluster</title>
      <link>/020_event_engine_setup/22_setup_eks.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/020_event_engine_setup/22_setup_eks.html</guid>
      <description>Set up the Elastic Kubernetes Service Cluster You can create your EKS Cluster using the eksctl cli or the AWS EKS console.
Follow the instructions described here to have your Cluster up and running.</description>
    </item>
    
    <item>
      <title>Prometheus and Grafana</title>
      <link>/050_kong_ingress_consumption_monitoring/051_prometheus_grafana.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/050_kong_ingress_consumption_monitoring/051_prometheus_grafana.html</guid>
      <description>Prometheus and Grafana Since we have Prometheus and Grafana already deployed where going to consume the Data Plane and monitor it from two perspectives:
 Kubernetes monitoring: monitor the Kong Data Plane Deployment in terms of resource consumption (CPU, memory and networking) Kong Data Plane monitoring: monitor the Kong Data Plane in terms of API consumption including number of processed requests, latency times, etc.  Kubernetes Monitoring and HPA Fortio Use Fortio to start injecting some request to the Data Plane</description>
    </item>
    
    <item>
      <title>ELK</title>
      <link>/050_kong_ingress_consumption_monitoring/052_elk.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/050_kong_ingress_consumption_monitoring/052_elk.html</guid>
      <description>ELK Stack Now let&amp;rsquo;s use ELK Stack to receive and work with all requests coming from the Kong Data Planes
Create an ELK Index $ kubectl get service kibana-kibana --output=jsonpath=&amp;#39;{.status.loadBalancer.ingress[0].hostname}&amp;#39; -n elk a39e2c2d48c044a67bc5f45e22c67b09-669447722.us-east-1.elb.amazonaws.com Redirect your browser to the Load Balancer instantiated for it: http://a39e2c2d48c044a67bc5f45e22c67b09-669447722.us-east-1.elb.amazonaws.com:5601
Click on Explore on my own On the left menu click on Management -&amp;gt; Stack Management
Click on Data -&amp;gt; Index Management. Since we&amp;rsquo;re already send requests to the Data Plane and we have enabled the TCP-Log plugin, we should see the kong index as we set in our Logstash configuration.</description>
    </item>
    
  </channel>
</rss>
